{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "# Chess Dataset Generation\n",
    "\n",
    "This notebook generates chess board state datasets for training the equilibrium propagation model.\n",
    "\n",
    "We create two types of datasets:\n",
    "1. **Board State Datasets**: Random chess positions for static position evaluation\n",
    "2. **Sequence Datasets**: Time-series of game states for learning game dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from src.chess import (\n",
    "    encode_onehot_gamestate,\n",
    "    generate_random_board_states,\n",
    "    generate_game_sequence,\n",
    "    generate_multiple_game_sequences,\n",
    "    ChessBoardDataset,\n",
    "    ChessSequenceDataset,\n",
    "    create_random_board_dataset,\n",
    "    create_game_sequence_dataset,\n",
    ")\n",
    "import chess\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set the parameters for dataset generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /Users/c/eq-chess/notebooks/scratch\n",
      "Board states: 10000\n",
      "Game sequences: 1000\n",
      "Split ratios - Train: 0.7, Val: 0.15, Test: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "SCRATCH_DIR = Path('scratch')\n",
    "SCRATCH_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Board state dataset parameters\n",
    "NUM_BOARD_STATES = 10000  # Total number of random board positions\n",
    "MAX_MOVES_FROM_START = 30  # Maximum random moves from starting position\n",
    "\n",
    "# Sequence dataset parameters\n",
    "NUM_GAME_SEQUENCES = 1000  # Number of game sequences\n",
    "HALF_MOVES_PER_GAME = 60   # Number of half-moves (plies) per game\n",
    "\n",
    "# Train/val/test split ratios\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "print(f\"Output directory: {SCRATCH_DIR.absolute()}\")\n",
    "print(f\"Board states: {NUM_BOARD_STATES}\")\n",
    "print(f\"Game sequences: {NUM_GAME_SEQUENCES}\")\n",
    "print(f\"Split ratios - Train: {TRAIN_RATIO}, Val: {VAL_RATIO}, Test: {TEST_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Test Encoding Function\n",
    "\n",
    "Verify that the board encoding works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding shape: torch.Size([8, 8, 12])\n",
      "Expected shape: (8, 8, 12)\n",
      "Encoding dtype: torch.float32\n",
      "Total pieces encoded: 32.0\n",
      "Expected total (32 pieces): 32\n",
      "\n",
      "White pawns (channel 0, rank 1):\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "\n",
      "Black pawns (channel 6, rank 6):\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Test with starting position\n",
    "test_board = chess.Board()\n",
    "encoding = encode_onehot_gamestate(test_board)\n",
    "\n",
    "print(f\"Encoding shape: {encoding.shape}\")\n",
    "print(f\"Expected shape: (8, 8, 12)\")\n",
    "print(f\"Encoding dtype: {encoding.dtype}\")\n",
    "print(f\"Total pieces encoded: {encoding.sum().item()}\")\n",
    "print(f\"Expected total (32 pieces): 32\")\n",
    "\n",
    "# Visualize a slice - white pawns (channel 0)\n",
    "print(\"\\nWhite pawns (channel 0, rank 1):\")\n",
    "print(encoding[1, :, 0])  # Should show pawns on rank 2 (index 1)\n",
    "\n",
    "print(\"\\nBlack pawns (channel 6, rank 6):\")\n",
    "print(encoding[6, :, 6])  # Should show pawns on rank 7 (index 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Generate Board State Dataset\n",
    "\n",
    "Create random chess positions for static position evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random board states...\n",
      "\n",
      "Board State Dataset Sizes:\n",
      "  Training:   7000\n",
      "  Validation: 1500\n",
      "  Test:       1500\n",
      "  Total:      10000\n",
      "\n",
      "Sample tensor shape: torch.Size([8, 8, 12])\n",
      "Sample tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating random board states...\")\n",
    "\n",
    "train_board_dataset, val_board_dataset, test_board_dataset = create_random_board_dataset(\n",
    "    num_boards=NUM_BOARD_STATES,\n",
    "    max_moves=MAX_MOVES_FROM_START,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(f\"\\nBoard State Dataset Sizes:\")\n",
    "print(f\"  Training:   {len(train_board_dataset)}\")\n",
    "print(f\"  Validation: {len(val_board_dataset)}\")\n",
    "print(f\"  Test:       {len(test_board_dataset)}\")\n",
    "print(f\"  Total:      {len(train_board_dataset) + len(val_board_dataset) + len(test_board_dataset)}\")\n",
    "\n",
    "# Test dataset access\n",
    "sample = train_board_dataset[0]\n",
    "print(f\"\\nSample tensor shape: {sample.shape}\")\n",
    "print(f\"Sample tensor dtype: {sample.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Generate Sequence Dataset\n",
    "\n",
    "Create game sequences for learning temporal dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating game sequences...\n",
      "\n",
      "Sequence Dataset Sizes:\n",
      "  Training:   700 sequences\n",
      "  Validation: 150 sequences\n",
      "  Test:       150 sequences\n",
      "  Total:      1000 sequences\n",
      "\n",
      "Sample sequence shape: torch.Size([61, 8, 8, 12])\n",
      "Sample sequence dtype: torch.float32\n",
      "Sequence length: 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating game sequences...\")\n",
    "\n",
    "train_seq_dataset, val_seq_dataset, test_seq_dataset = create_game_sequence_dataset(\n",
    "    num_games=NUM_GAME_SEQUENCES,\n",
    "    num_half_moves_per_game=HALF_MOVES_PER_GAME,\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(f\"\\nSequence Dataset Sizes:\")\n",
    "print(f\"  Training:   {len(train_seq_dataset)} sequences\")\n",
    "print(f\"  Validation: {len(val_seq_dataset)} sequences\")\n",
    "print(f\"  Test:       {len(test_seq_dataset)} sequences\")\n",
    "print(f\"  Total:      {len(train_seq_dataset) + len(val_seq_dataset) + len(test_seq_dataset)} sequences\")\n",
    "\n",
    "# Test sequence dataset access\n",
    "sample_seq = train_seq_dataset[0]\n",
    "print(f\"\\nSample sequence shape: {sample_seq.shape}\")\n",
    "print(f\"Sample sequence dtype: {sample_seq.dtype}\")\n",
    "print(f\"Sequence length: {sample_seq.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Save Datasets\n",
    "\n",
    "Save the datasets to disk for reuse in other notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving board state datasets...\n",
      "Saving sequence datasets...\n",
      "\n",
      "All datasets saved successfully!\n",
      "\n",
      "Saved files:\n",
      "  test_board_dataset.pt              4.20 MB\n",
      "  test_seq_dataset.pt               12.39 MB\n",
      "  train_board_dataset.pt            19.64 MB\n",
      "  train_seq_dataset.pt              57.63 MB\n",
      "  val_board_dataset.pt               4.21 MB\n",
      "  val_seq_dataset.pt                12.45 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving board state datasets...\")\n",
    "\n",
    "# Save board state datasets\n",
    "torch.save(train_board_dataset, SCRATCH_DIR / 'train_board_dataset.pt')\n",
    "torch.save(val_board_dataset, SCRATCH_DIR / 'val_board_dataset.pt')\n",
    "torch.save(test_board_dataset, SCRATCH_DIR / 'test_board_dataset.pt')\n",
    "\n",
    "print(\"Saving sequence datasets...\")\n",
    "\n",
    "# Save sequence datasets\n",
    "torch.save(train_seq_dataset, SCRATCH_DIR / 'train_seq_dataset.pt')\n",
    "torch.save(val_seq_dataset, SCRATCH_DIR / 'val_seq_dataset.pt')\n",
    "torch.save(test_seq_dataset, SCRATCH_DIR / 'test_seq_dataset.pt')\n",
    "\n",
    "print(\"\\nAll datasets saved successfully!\")\n",
    "print(\"\\nSaved files:\")\n",
    "for file in sorted(SCRATCH_DIR.glob('*.pt')):\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {file.name:<30} {size_mb:>8.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "Analyze the generated datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing dataset statistics...\n",
      "\n",
      "Board State Dataset Statistics:\n",
      "==================================================\n",
      "Average pieces per board: 31.37\n",
      "Min pieces: 27\n",
      "Max pieces: 32\n",
      "Std dev: 0.99\n",
      "\n",
      "Sequence Dataset Statistics:\n",
      "==================================================\n",
      "Average sequence length: 61.00\n",
      "Min sequence length: 61\n",
      "Max sequence length: 61\n",
      "Std dev: 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Computing dataset statistics...\\n\")\n",
    "\n",
    "# Board state statistics\n",
    "print(\"Board State Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Sample a few boards to compute average piece counts\n",
    "sample_size = min(100, len(train_board_dataset))\n",
    "piece_counts = []\n",
    "\n",
    "for i in range(sample_size):\n",
    "    encoding = train_board_dataset[i]\n",
    "    piece_count = encoding.sum().item()\n",
    "    piece_counts.append(piece_count)\n",
    "\n",
    "print(f\"Average pieces per board: {np.mean(piece_counts):.2f}\")\n",
    "print(f\"Min pieces: {np.min(piece_counts):.0f}\")\n",
    "print(f\"Max pieces: {np.max(piece_counts):.0f}\")\n",
    "print(f\"Std dev: {np.std(piece_counts):.2f}\")\n",
    "\n",
    "# Sequence statistics\n",
    "print(\"\\nSequence Dataset Statistics:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "sample_size = min(100, len(train_seq_dataset))\n",
    "seq_lengths = []\n",
    "\n",
    "for i in range(sample_size):\n",
    "    seq = train_seq_dataset[i]\n",
    "    seq_lengths.append(seq.shape[0])\n",
    "\n",
    "print(f\"Average sequence length: {np.mean(seq_lengths):.2f}\")\n",
    "print(f\"Min sequence length: {np.min(seq_lengths):.0f}\")\n",
    "print(f\"Max sequence length: {np.max(seq_lengths):.0f}\")\n",
    "print(f\"Std dev: {np.std(seq_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Example: Loading Saved Datasets\n",
    "\n",
    "Demonstrate how to load the datasets in other notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Loading saved datasets\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_train_board = torch.load(SCRATCH_DIR / 'train_board_dataset.pt')\n",
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_val_board = torch.load(SCRATCH_DIR / 'val_board_dataset.pt')\n",
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_test_board = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
      "9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_val_board = torch.load(SCRATCH_DIR / 'val_board_dataset.pt')\n",
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_test_board = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
      "\n",
      "  loaded_train_seq = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.ers/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_test_board = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
      "\n",
      "  loaded_train_seq = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
      "\n",
      "  loaded_val_seq = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
      "1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.ers/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_18832/3490568215.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_test_board = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
      "\n",
      "  loaded_train_seq = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
      "\n",
      "  loaded_val_seq = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
      "\n",
      "  loaded_test_seq = torch.load(SCRATCH_DIR / 'test_seq_dataset.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded board state datasets:\n",
      "  Train: 7000\n",
      "  Val:   1500\n",
      "  Test:  1500\n",
      "\n",
      "Loaded sequence datasets:\n",
      "  Train: 700\n",
      "  Val:   150\n",
      "  Test:  150\n",
      "\n",
      "Datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Example: Loading saved datasets\\n\")\n",
    "\n",
    "# Load board state datasets\n",
    "loaded_train_board = torch.load(SCRATCH_DIR / 'train_board_dataset.pt')\n",
    "loaded_val_board = torch.load(SCRATCH_DIR / 'val_board_dataset.pt')\n",
    "loaded_test_board = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
    "\n",
    "# Load sequence datasets\n",
    "loaded_train_seq = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
    "loaded_val_seq = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
    "loaded_test_seq = torch.load(SCRATCH_DIR / 'test_seq_dataset.pt')\n",
    "\n",
    "print(\"Loaded board state datasets:\")\n",
    "print(f\"  Train: {len(loaded_train_board)}\")\n",
    "print(f\"  Val:   {len(loaded_val_board)}\")\n",
    "print(f\"  Test:  {len(loaded_test_board)}\")\n",
    "\n",
    "print(\"\\nLoaded sequence datasets:\")\n",
    "print(f\"  Train: {len(loaded_train_seq)}\")\n",
    "print(f\"  Val:   {len(loaded_val_seq)}\")\n",
    "print(f\"  Test:  {len(loaded_test_seq)}\")\n",
    "\n",
    "print(\"\\nDatasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Example: Using with DataLoader\n",
    "\n",
    "Show how to use these datasets with PyTorch DataLoaders for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader created:\n",
      "  Batch size: 32\n",
      "  Training batches: 219\n",
      "  Validation batches: 47\n",
      "\n",
      "Sample batch shape: torch.Size([32, 8, 8, 12])\n",
      "Expected: (32, 8, 8, 12)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    loaded_train_board,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # Set to 0 for compatibility, increase for faster loading\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    loaded_val_board,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Test batch retrieval\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shape: {batch.shape}\")\n",
    "print(f\"Expected: ({batch_size}, 8, 8, 12)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Visualize a Chess Position\n",
    "\n",
    "Optionally visualize one of the generated positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample chess position:\n",
      "r . b q k b n r\n",
      "p p p p p . p .\n",
      ". . n . . p . .\n",
      ". . . . . . . p\n",
      "Q P . . P . . P\n",
      ". . P . . . . .\n",
      "P . . P . P P .\n",
      "R N B . K B N R\n",
      "\n",
      "FEN: r1bqkbnr/ppppp1p1/2n2p2/7p/QP2P2P/2P5/P2P1PP1/RNB1KBNR w KQ - 1 6\n",
      "Legal moves: 34\n",
      "Turn: White\n",
      "Game over: False\n"
     ]
    }
   ],
   "source": [
    "# Get a random board from the training dataset\n",
    "sample_board = train_board_dataset.boards[0]\n",
    "\n",
    "print(\"Sample chess position:\")\n",
    "print(sample_board)\n",
    "print(f\"\\nFEN: {sample_board.fen()}\")\n",
    "print(f\"Legal moves: {len(list(sample_board.legal_moves))}\")\n",
    "print(f\"Turn: {'White' if sample_board.turn else 'Black'}\")\n",
    "print(f\"Game over: {sample_board.is_game_over()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "Datasets have been generated and saved to `notebooks/scratch/`. You can now load them in other notebooks using:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "SCRATCH_DIR = Path('scratch')\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = torch.load(SCRATCH_DIR / 'train_board_dataset.pt')\n",
    "val_dataset = torch.load(SCRATCH_DIR / 'val_board_dataset.pt')\n",
    "test_dataset = torch.load(SCRATCH_DIR / 'test_board_dataset.pt')\n",
    "\n",
    "# Or for sequences\n",
    "train_seq = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
    "val_seq = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
    "test_seq = torch.load(SCRATCH_DIR / 'test_seq_dataset.pt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
