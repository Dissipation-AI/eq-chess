{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "# Chess EqProp Training\n",
    "\n",
    "Train the holomorphic equilibrium propagation model on chess positions using PyTorch Lightning and Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c/eq-chess/env/lib/python3.11/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/c/eq-chess/env/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <EB3FF92A-5EB1-3EE8-AF8B-5923C1265422> /Users/c/eq-chess/env/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/c/eq-chess/env/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/c/eq-chess/env/lib/python3.11/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/c/eq-chess/env/lib/python3.11/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/c/eq-chess/env/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "PyTorch Lightning version: 2.5.6\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "import wandb\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "from src.eqprop import LinearHolomorphicEQProp\n",
    "import chess\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"Device: {torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set all hyperparameters and training configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: Input=768, Hidden=2048, Output=6912\n",
      "  Output breakdown: 8 history states + 1 future state = 9 total states\n",
      "  Total output dimensions: 9 × 768 = 6912\n",
      "  EqProp: T1=20, T2=4, N=4, beta=0.5\n",
      "  Holomorphic EP: Using 4 phases on unit circle with complex dynamics\n",
      "  Training: Batch=16, Epochs=100, LR=0.001\n",
      "  State init: zeros\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "SCRATCH_DIR = Path('scratch')\n",
    "CHECKPOINT_DIR = Path('checkpoints')\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Model architecture\n",
    "INPUT_SIZE = 8 * 8 * 12   # Chess board encoding (768)\n",
    "HIDDEN_SIZE = 2048        # Hidden layer size\n",
    "\n",
    "# Output structure: [8 previous board states] + [1 next board state]\n",
    "# Network always predicts from white's perspective\n",
    "BOARD_STATE_SIZE = 8 * 8 * 12  # 768 per board\n",
    "NUM_HISTORY_STATES = 8         # Predict last 8 board states (8 half-moves of history)\n",
    "NUM_FUTURE_STATES = 1          # Predict next board state\n",
    "TOTAL_OUTPUT_STATES = NUM_HISTORY_STATES + NUM_FUTURE_STATES  # 9 total states\n",
    "OUTPUT_SIZE = TOTAL_OUTPUT_STATES * BOARD_STATE_SIZE  # 9 * 768 = 6912\n",
    "\n",
    "WEIGHT_STD = 0.05        # Weight initialization std (smaller for larger output)\n",
    "\n",
    "# EqProp dynamics parameters\n",
    "T1 = 20          # Free phase settling time\n",
    "T2 = 4           # Nudged phase settling time\n",
    "N = 4            # Number of holomorphic phases (1=standard EP, 4=holomorphic)\n",
    "                 # ✓ N>1 now properly implemented with complex dynamics!\n",
    "BETA = 0.5       # Nudging strength\n",
    "LR_DYNAMICS = 0.5    # Learning rate for state dynamics\n",
    "NOISE_STD = 0.0      # Noise during dynamics (0 = no noise)\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 16  # Smaller batch due to larger output\n",
    "NUM_EPOCHS = 100\n",
    "LR_LEARNING = 0.001  # Learning rate for weight updates\n",
    "\n",
    "# State initialization configuration\n",
    "STATE_INIT_MODE = 'zeros'  # 'zeros', 'random', 'custom'\n",
    "STATE_INIT_STD = 0.01      # Std for random initialization\n",
    "\n",
    "# Wandb configuration\n",
    "WANDB_PROJECT = 'eq-chess'\n",
    "WANDB_ENTITY = None  # Set to your wandb username/team\n",
    "EXPERIMENT_NAME = 'eqprop-history-prediction'\n",
    "\n",
    "# Hardware\n",
    "ACCELERATOR = 'auto'  # 'auto', 'cpu', 'gpu', 'mps'\n",
    "NUM_WORKERS = 0       # DataLoader workers (0 for debugging)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: Input={INPUT_SIZE}, Hidden={HIDDEN_SIZE}, Output={OUTPUT_SIZE}\")\n",
    "print(f\"  Output breakdown: {NUM_HISTORY_STATES} history states + {NUM_FUTURE_STATES} future state = {TOTAL_OUTPUT_STATES} total states\")\n",
    "print(f\"  Total output dimensions: {TOTAL_OUTPUT_STATES} × {BOARD_STATE_SIZE} = {OUTPUT_SIZE}\")\n",
    "print(f\"  EqProp: T1={T1}, T2={T2}, N={N}, beta={BETA}\")\n",
    "print(f\"  Holomorphic EP: Using {N} phases on unit circle with complex dynamics\")\n",
    "print(f\"  Training: Batch={BATCH_SIZE}, Epochs={NUM_EPOCHS}, LR={LR_LEARNING}\")\n",
    "print(f\"  State init: {STATE_INIT_MODE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Load Datasets\n",
    "\n",
    "Load the pre-generated chess datasets from the scratch directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_34319/897292080.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_seq_dataset = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
      "/var/folders/rb/x1hdwk9138lbks3c2gr1f9gr0000gn/T/ipykernel_34319/897292080.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_seq_dataset = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
      "6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  val_seq_dataset = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
      "\n",
      "  test_seq_dataset = torch.load(SCRATCH_DIR / 'test_seq_dataset.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence dataset sizes:\n",
      "  Train: 700\n",
      "  Val:   150\n",
      "  Test:  150\n",
      "Created 36159 training samples from 700 sequences\n",
      "Created 7800 training samples from 150 sequences\n",
      "Created 7771 training samples from 150 sequences\n",
      "\n",
      "Batches per epoch:\n",
      "  Train: 2260\n",
      "  Val:   488\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading datasets...\\n\")\n",
    "\n",
    "# Load SEQUENCE datasets (not board states)\n",
    "train_seq_dataset = torch.load(SCRATCH_DIR / 'train_seq_dataset.pt')\n",
    "val_seq_dataset = torch.load(SCRATCH_DIR / 'val_seq_dataset.pt')\n",
    "test_seq_dataset = torch.load(SCRATCH_DIR / 'test_seq_dataset.pt')\n",
    "\n",
    "print(f\"Sequence dataset sizes:\")\n",
    "print(f\"  Train: {len(train_seq_dataset)}\")\n",
    "print(f\"  Val:   {len(val_seq_dataset)}\")\n",
    "print(f\"  Test:  {len(test_seq_dataset)}\")\n",
    "\n",
    "# We need to create a custom dataset that extracts training samples from sequences\n",
    "# Each sample: input = board state, target = [8 history states] + [1 next state]\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChessHistoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that creates training samples from game sequences.\n",
    "    Each sample consists of:\n",
    "    - Input: Current board state (from white's perspective)\n",
    "    - Target: [8 previous states] + [1 next state] (9 total states)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_dataset, num_history=8):\n",
    "        self.sequences = sequence_dataset.sequences\n",
    "        self.num_history = num_history\n",
    "        self.samples = []\n",
    "        \n",
    "        # Extract valid training positions from sequences\n",
    "        for seq_idx, sequence in enumerate(self.sequences):\n",
    "            # Need at least num_history + 1 positions (history + current + next)\n",
    "            if len(sequence) < num_history + 2:\n",
    "                continue\n",
    "            \n",
    "            # Create samples from positions that have enough history and a next state\n",
    "            for pos_idx in range(num_history, len(sequence) - 1):\n",
    "                self.samples.append((seq_idx, pos_idx))\n",
    "        \n",
    "        print(f\"Created {len(self.samples)} training samples from {len(self.sequences)} sequences\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def flip_board_for_white_perspective(self, board):\n",
    "        \"\"\"\n",
    "        Flip board representation so it's always from white's perspective.\n",
    "        If it's black's turn, flip the board vertically and swap colors.\n",
    "        \"\"\"\n",
    "        from src.chess import encode_onehot_gamestate\n",
    "        \n",
    "        encoding = encode_onehot_gamestate(board)  # (8, 8, 12)\n",
    "        \n",
    "        if board.turn == chess.BLACK:\n",
    "            # Flip board vertically (rank 0 <-> rank 7)\n",
    "            encoding = torch.flip(encoding, dims=[0])\n",
    "            # Swap white and black channels (0-5 <-> 6-11)\n",
    "            white_channels = encoding[:, :, 0:6].clone()\n",
    "            black_channels = encoding[:, :, 6:12].clone()\n",
    "            encoding[:, :, 0:6] = black_channels\n",
    "            encoding[:, :, 6:12] = white_channels\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, pos_idx = self.samples[idx]\n",
    "        sequence = self.sequences[seq_idx]\n",
    "        \n",
    "        # Current position (input)\n",
    "        current_board = sequence[pos_idx]\n",
    "        input_encoding = self.flip_board_for_white_perspective(current_board)\n",
    "        \n",
    "        # History states (8 previous positions)\n",
    "        history_encodings = []\n",
    "        for i in range(NUM_HISTORY_STATES):\n",
    "            hist_idx = pos_idx - NUM_HISTORY_STATES + i\n",
    "            hist_board = sequence[hist_idx]\n",
    "            hist_encoding = self.flip_board_for_white_perspective(hist_board)\n",
    "            history_encodings.append(hist_encoding.flatten())\n",
    "        \n",
    "        # Next state (1 future position)\n",
    "        next_board = sequence[pos_idx + 1]\n",
    "        next_encoding = self.flip_board_for_white_perspective(next_board)\n",
    "        next_flat = next_encoding.flatten()\n",
    "        \n",
    "        # Combine history + next state\n",
    "        # Output: [state_-7, state_-6, ..., state_-1, state_+1]\n",
    "        target = torch.cat(history_encodings + [next_flat])\n",
    "        \n",
    "        return input_encoding, target\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ChessHistoryDataset(train_seq_dataset, num_history=NUM_HISTORY_STATES)\n",
    "val_dataset = ChessHistoryDataset(val_seq_dataset, num_history=NUM_HISTORY_STATES)\n",
    "test_dataset = ChessHistoryDataset(test_seq_dataset, num_history=NUM_HISTORY_STATES)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nBatches per epoch:\")\n",
    "print(f\"  Train: {len(train_loader)}\")\n",
    "print(f\"  Val:   {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## PyTorch Lightning Module\n",
    "\n",
    "Wrapper for the EqProp model with Lightning training logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChessEqPropLightning module defined.\n"
     ]
    }
   ],
   "source": [
    "class ChessEqPropLightning(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    PyTorch Lightning module for training chess EqProp model.\n",
    "    Predicts 8 historical board states + 1 next board state from current position.\n",
    "    All from white's perspective.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters(config)\n",
    "        \n",
    "        # Extract config\n",
    "        self.input_size = config['input_size']\n",
    "        self.hidden_size = config['hidden_size']\n",
    "        self.output_size = config['output_size']\n",
    "        self.board_state_size = config.get('board_state_size', 768)\n",
    "        self.num_history_states = config.get('num_history_states', 8)\n",
    "        self.num_future_states = config.get('num_future_states', 1)\n",
    "        self.total_output_states = config.get('total_output_states', 9)\n",
    "        \n",
    "        self.T1 = config['T1']\n",
    "        self.T2 = config['T2']\n",
    "        self.N = config['N']\n",
    "        self.beta = config['beta']\n",
    "        self.lr_dynamics = config['lr_dynamics']\n",
    "        self.lr_learning = config['lr_learning']\n",
    "        self.noise_std = config['noise_std']\n",
    "        \n",
    "        self.state_init_mode = config.get('state_init_mode', 'zeros')\n",
    "        self.state_init_std = config.get('state_init_std', 0.01)\n",
    "        \n",
    "        # Create EqProp model\n",
    "        self.model = LinearHolomorphicEQProp(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            output_size=self.output_size,\n",
    "            weight_std=config.get('weight_std', 0.1)\n",
    "        )\n",
    "        \n",
    "        # Loss function\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def configure_state(self, batch_size: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Configure/reset the model state.\n",
    "        \n",
    "        This is where you can implement custom state initialization.\n",
    "        Called at the beginning of each forward pass or can be called manually.\n",
    "        \n",
    "        Args:\n",
    "            batch_size: If provided, configure for batched processing\n",
    "        \"\"\"\n",
    "        if self.state_init_mode == 'zeros':\n",
    "            self.model.state.zero_()\n",
    "        elif self.state_init_mode == 'random':\n",
    "            self.model.state.normal_(0, self.state_init_std)\n",
    "            # Keep input state at zero\n",
    "            self.model.state[:self.input_size] = 0.0\n",
    "        elif self.state_init_mode == 'custom':\n",
    "            # Custom state initialization\n",
    "            self.model.state.zero_()\n",
    "            # Initialize output state with prior over history reconstruction\n",
    "            # Bias toward more recent states being more accurate\n",
    "            o_start = self.input_size + self.hidden_size\n",
    "            \n",
    "            # History states: more recent = less noise\n",
    "            for i in range(self.num_history_states):\n",
    "                # More recent history (higher i) gets smaller initialization noise\n",
    "                noise_scale = 0.01 * (1.0 - i / self.num_history_states)\n",
    "                start_idx = o_start + i * self.board_state_size\n",
    "                end_idx = start_idx + self.board_state_size\n",
    "                self.model.state[start_idx:end_idx] = torch.randn(self.board_state_size) * noise_scale\n",
    "            \n",
    "            # Future state: slightly higher noise (it's a prediction)\n",
    "            future_start = o_start + self.num_history_states * self.board_state_size\n",
    "            future_end = future_start + self.board_state_size\n",
    "            self.model.state[future_start:future_end] = torch.randn(self.board_state_size) * 0.02\n",
    "\n",
    "    def parse_output(self, output: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Parse model output into history states and next state prediction.\n",
    "        \n",
    "        Args:\n",
    "            output: Output tensor (output_size,) or (batch_size, output_size)\n",
    "        \n",
    "        Returns:\n",
    "            (history_states, next_state)\n",
    "        \"\"\"\n",
    "        if output.dim() == 1:\n",
    "            # Single sample\n",
    "            output_reshaped = output.reshape(self.total_output_states, self.board_state_size)\n",
    "            history = output_reshaped[:self.num_history_states]  # First 8 states\n",
    "            next_state = output_reshaped[self.num_history_states:]  # Last 1 state\n",
    "            return history, next_state\n",
    "        else:\n",
    "            # Batch\n",
    "            batch_size = output.shape[0]\n",
    "            output_reshaped = output.reshape(batch_size, self.total_output_states, self.board_state_size)\n",
    "            history = output_reshaped[:, :self.num_history_states, :]  # First 8 states\n",
    "            next_state = output_reshaped[:, self.num_history_states:, :]  # Last 1 state\n",
    "            return history, next_state\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor (batch_size, 8, 8, 12) - chess board encoding\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        # Flatten board encoding\n",
    "        batch_size = x.shape[0]\n",
    "        x_flat = x.reshape(batch_size, -1)  # (batch_size, 768)\n",
    "        \n",
    "        # Process each sample in batch\n",
    "        outputs = []\n",
    "        for i in range(batch_size):\n",
    "            # Configure state for this sample\n",
    "            self.configure_state()\n",
    "            \n",
    "            # Forward pass (settles to equilibrium)\n",
    "            output = self.model.evaluate(\n",
    "                x_flat[i],\n",
    "                noise_std=0.0,  # No noise during inference\n",
    "                T_settle=self.T1,\n",
    "                lr_dynamics=self.lr_dynamics\n",
    "            )\n",
    "            outputs.append(output)\n",
    "        \n",
    "        return torch.stack(outputs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Training step using equilibrium propagation.\n",
    "        \"\"\"\n",
    "        # batch = (input, target)\n",
    "        # input: (batch_size, 8, 8, 12)\n",
    "        # target: (batch_size, output_size) = (batch_size, 9 * 768)\n",
    "        x, targets = batch\n",
    "        batch_size = x.shape[0]\n",
    "        x_flat = x.reshape(batch_size, -1)\n",
    "        \n",
    "        # Train each sample with EqProp\n",
    "        total_loss = 0.0\n",
    "        total_history_loss = 0.0\n",
    "        total_next_loss = 0.0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Configure state\n",
    "            self.configure_state()\n",
    "            \n",
    "            # Set input\n",
    "            self.model.set_inputs(x_flat[i])\n",
    "            \n",
    "            # Create mask: apply stronger supervision to next state prediction than history\n",
    "            mask = torch.ones_like(targets[i])\n",
    "            history_size = self.num_history_states * self.board_state_size\n",
    "            mask[:history_size] = 0.3  # Lower weight on history reconstruction\n",
    "            mask[history_size:] = 1.0  # Full weight on next state prediction\n",
    "            \n",
    "            # Perform EqProp learning\n",
    "            self.model.learn(\n",
    "                target=targets[i],\n",
    "                mask=mask,\n",
    "                beta=self.beta,\n",
    "                T1=self.T1,\n",
    "                T2=self.T2,\n",
    "                N=self.N,\n",
    "                lr_dynamics=self.lr_dynamics,\n",
    "                lr_learning=self.lr_learning,\n",
    "                noise_std=self.noise_std\n",
    "            )\n",
    "            \n",
    "            # Compute losses for logging\n",
    "            with torch.no_grad():\n",
    "                output = self.model.output_state\n",
    "                \n",
    "                # Parse output\n",
    "                pred_history, pred_next = self.parse_output(output)\n",
    "                target_history, target_next = self.parse_output(targets[i])\n",
    "                \n",
    "                # History reconstruction loss (MSE)\n",
    "                history_loss = self.mse_loss(pred_history, target_history)\n",
    "                \n",
    "                # Next state prediction loss (MSE)\n",
    "                next_loss = self.mse_loss(pred_next, target_next)\n",
    "                \n",
    "                # Combined loss\n",
    "                loss = 0.3 * history_loss + next_loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_history_loss += history_loss.item()\n",
    "                total_next_loss += next_loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / batch_size\n",
    "        avg_history_loss = total_history_loss / batch_size\n",
    "        avg_next_loss = total_next_loss / batch_size\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', avg_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_history_loss', avg_history_loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_next_loss', avg_next_loss, on_step=False, on_epoch=True)\n",
    "        \n",
    "        return {'loss': avg_loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step - inference only.\n",
    "        \"\"\"\n",
    "        x, targets = batch\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = self.forward(x)\n",
    "        \n",
    "        # Compute losses\n",
    "        total_history_loss = 0.0\n",
    "        total_next_loss = 0.0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            pred_history, pred_next = self.parse_output(outputs[i])\n",
    "            target_history, target_next = self.parse_output(targets[i])\n",
    "            \n",
    "            # History reconstruction loss\n",
    "            history_loss = self.mse_loss(pred_history, target_history)\n",
    "            total_history_loss += history_loss.item()\n",
    "            \n",
    "            # Next state prediction loss\n",
    "            next_loss = self.mse_loss(pred_next, target_next)\n",
    "            total_next_loss += next_loss.item()\n",
    "        \n",
    "        avg_history_loss = total_history_loss / batch_size\n",
    "        avg_next_loss = total_next_loss / batch_size\n",
    "        avg_loss = 0.3 * avg_history_loss + avg_next_loss\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', avg_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_history_loss', avg_history_loss, on_epoch=True)\n",
    "        self.log('val_next_loss', avg_next_loss, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return {'val_loss': avg_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Configure optimizer.\n",
    "        \n",
    "        Note: EqProp handles its own weight updates, so this is primarily\n",
    "        for compatibility with Lightning. We use a dummy optimizer.\n",
    "        \"\"\"\n",
    "        # Return a dummy optimizer since EqProp handles updates internally\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.0)\n",
    "        return optimizer\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Called at the end of training epoch.\"\"\"\n",
    "        # Log weight statistics\n",
    "        with torch.no_grad():\n",
    "            W = self.model.W\n",
    "            self.log('weight_mean', W.mean())\n",
    "            self.log('weight_std', W.std())\n",
    "            self.log('weight_max', W.max())\n",
    "            self.log('weight_min', W.min())\n",
    "\n",
    "print(\"ChessEqPropLightning module defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Initialize Model\n",
    "\n",
    "Create the model with configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created:\n",
      "  Total parameters: 94,633,984\n",
      "  Total state size: 9,728\n",
      "  Weight matrix shape: torch.Size([9728, 9728])\n",
      "\n",
      "  Output structure:\n",
      "    - History states: 8 × 768 = 6144\n",
      "    - Next state:     1 × 768 = 768\n",
      "    - Total output:   9 × 768 = 6912\n"
     ]
    }
   ],
   "source": [
    "# Configuration dictionary\n",
    "config = {\n",
    "    'input_size': INPUT_SIZE,\n",
    "    'hidden_size': HIDDEN_SIZE,\n",
    "    'output_size': OUTPUT_SIZE,\n",
    "    'board_state_size': BOARD_STATE_SIZE,\n",
    "    'num_history_states': NUM_HISTORY_STATES,\n",
    "    'num_future_states': NUM_FUTURE_STATES,\n",
    "    'total_output_states': TOTAL_OUTPUT_STATES,\n",
    "    'weight_std': WEIGHT_STD,\n",
    "    'T1': T1,\n",
    "    'T2': T2,\n",
    "    'N': N,\n",
    "    'beta': BETA,\n",
    "    'lr_dynamics': LR_DYNAMICS,\n",
    "    'lr_learning': LR_LEARNING,\n",
    "    'noise_std': NOISE_STD,\n",
    "    'state_init_mode': STATE_INIT_MODE,\n",
    "    'state_init_std': STATE_INIT_STD,\n",
    "}\n",
    "\n",
    "# Create model\n",
    "model = ChessEqPropLightning(config)\n",
    "\n",
    "print(f\"Model created:\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Total state size: {model.model.total_size:,}\")\n",
    "print(f\"  Weight matrix shape: {model.model.W.shape}\")\n",
    "print(f\"\\n  Output structure:\")\n",
    "print(f\"    - History states: {NUM_HISTORY_STATES} × {BOARD_STATE_SIZE} = {NUM_HISTORY_STATES * BOARD_STATE_SIZE}\")\n",
    "print(f\"    - Next state:     {NUM_FUTURE_STATES} × {BOARD_STATE_SIZE} = {NUM_FUTURE_STATES * BOARD_STATE_SIZE}\")\n",
    "print(f\"    - Total output:   {TOTAL_OUTPUT_STATES} × {BOARD_STATE_SIZE} = {OUTPUT_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Setup Wandb Logging\n",
    "\n",
    "Initialize Weights & Biases for experiment tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharles-s-strauss\u001b[0m (\u001b[33mcharles-s-strauss-n-a\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/c/eq-chess/notebooks/wandb/run-20251123_163158-xa365r14</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/charles-s-strauss-n-a/eq-chess/runs/xa365r14' target=\"_blank\">eqprop-history-prediction</a></strong> to <a href='https://wandb.ai/charles-s-strauss-n-a/eq-chess' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/charles-s-strauss-n-a/eq-chess' target=\"_blank\">https://wandb.ai/charles-s-strauss-n-a/eq-chess</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/charles-s-strauss-n-a/eq-chess/runs/xa365r14' target=\"_blank\">https://wandb.ai/charles-s-strauss-n-a/eq-chess/runs/xa365r14</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb initialized.\n",
      "  Project: eq-chess\n",
      "  Run name: eqprop-history-prediction\n",
      "  Run URL: https://wandb.ai/charles-s-strauss-n-a/eq-chess/runs/xa365r14\n"
     ]
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    entity=WANDB_ENTITY,\n",
    "    name=EXPERIMENT_NAME,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(\"Wandb initialized.\")\n",
    "print(f\"  Project: {WANDB_PROJECT}\")\n",
    "print(f\"  Run name: {EXPERIMENT_NAME}\")\n",
    "print(f\"  Run URL: {wandb.run.get_url() if wandb.run else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Train Model\n",
    "\n",
    "Run the manual EqProp training loop.\n",
    "\n",
    "This directly calls `model.learn()` for each sample, which performs:\n",
    "1. Free phase: Settle to equilibrium with beta=0\n",
    "2. Nudged phase(s): Settle with beta (holomorphic N-phase sampling)\n",
    "3. Weight update: Based on difference between free and nudged equilibria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]:   0%|                     | 4/2260 [01:22<12:43:52, 20.32s/it, loss=1.2595, hist=0.9726, next=0.9677] hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]1:02<13:08:11, 20.94s/it, loss=1.2587, hist=0.9710, next=0.9674]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 3/2260 [01:02<12:54:09, 20.58s/it, loss=1.2587, hist=0.9710, next=0.9674]9, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]1:02<13:08:11, 20.94s/it, loss=1.2587, hist=0.9710, next=0.9674]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]22<12:54:09, 20.58s/it, loss=1.2595, hist=0.9726, next=0.9677]9, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]1:02<13:08:11, 20.94s/it, loss=1.2587, hist=0.9710, next=0.9674]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 3/2260 [01:02<12:54:09, 20.58s/it, loss=1.2587, hist=0.9710, next=0.9674]9, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]1:02<13:08:11, 20.94s/it, loss=1.2587, hist=0.9710, next=0.9674]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]Epoch 1/100 [Train]:   0%|                     | 2/2260 [00:42<13:08:11, 20.94s/it, loss=1.2589, hist=0.9743, next=0.9666]ext=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]:   0%|                     | 1/2260 [00:42<13:52:57, 22.12s/it, loss=1.2589, hist=0.9743, next=0.9666]619, hist=0.9735, next=0.9699]| 1/2260 [00:22<13:52:57, 22.12s/it, loss=1.2619, hist=0.9735, next=0.9699]60 [00:22<?, ?it/s, loss=1.2619, hist=0.9735, next=0.9699]"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "# Manual EqProp training loop\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_history_loss': [],\n",
    "    'train_next_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_history_loss': [],\n",
    "    'val_next_loss': [],\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # ========== Training Phase ==========\n",
    "    model.model.train()\n",
    "    train_loss = 0.0\n",
    "    train_history_loss = 0.0\n",
    "    train_next_loss = 0.0\n",
    "    num_train_samples = 0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
    "    for batch_idx, (x, targets) in enumerate(train_pbar):\n",
    "        batch_size = x.shape[0]\n",
    "        x_flat = x.reshape(batch_size, -1)\n",
    "        \n",
    "        # Move to device\n",
    "        if torch.backends.mps.is_available():\n",
    "            x_flat = x_flat.to('mps')\n",
    "            targets = targets.to('mps')\n",
    "            model.model = model.model.to('mps')\n",
    "        elif torch.cuda.is_available():\n",
    "            x_flat = x_flat.cuda()\n",
    "            targets = targets.cuda()\n",
    "            model.model = model.model.cuda()\n",
    "        \n",
    "        # Train each sample with EqProp\n",
    "        batch_loss = 0.0\n",
    "        batch_history_loss = 0.0\n",
    "        batch_next_loss = 0.0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # Configure state\n",
    "            model.configure_state()\n",
    "            \n",
    "            # Set input\n",
    "            model.model.set_inputs(x_flat[i])\n",
    "            \n",
    "            # Create mask: stronger supervision on next state\n",
    "            mask = torch.ones_like(targets[i])\n",
    "            history_size = NUM_HISTORY_STATES * BOARD_STATE_SIZE\n",
    "            mask[:history_size] = 0.3  # Lower weight on history\n",
    "            mask[history_size:] = 1.0  # Full weight on next state\n",
    "            \n",
    "            # Perform EqProp learning (this updates weights)\n",
    "            model.model.learn(\n",
    "                target=targets[i],\n",
    "                mask=mask,\n",
    "                beta=BETA,\n",
    "                T1=T1,\n",
    "                T2=T2,\n",
    "                N=N,\n",
    "                lr_dynamics=LR_DYNAMICS,\n",
    "                lr_learning=LR_LEARNING,\n",
    "                noise_std=NOISE_STD\n",
    "            )\n",
    "            \n",
    "            # Compute losses for logging\n",
    "            with torch.no_grad():\n",
    "                output = model.model.output_state\n",
    "                pred_history, pred_next = model.parse_output(output)\n",
    "                target_history, target_next = model.parse_output(targets[i])\n",
    "                \n",
    "                history_loss = model.mse_loss(pred_history, target_history)\n",
    "                next_loss = model.mse_loss(pred_next, target_next)\n",
    "                loss = 0.3 * history_loss + next_loss\n",
    "                \n",
    "                batch_loss += loss.item()\n",
    "                batch_history_loss += history_loss.item()\n",
    "                batch_next_loss += next_loss.item()\n",
    "        \n",
    "        # Average over batch\n",
    "        avg_batch_loss = batch_loss / batch_size\n",
    "        avg_batch_history_loss = batch_history_loss / batch_size\n",
    "        avg_batch_next_loss = batch_next_loss / batch_size\n",
    "        \n",
    "        train_loss += batch_loss\n",
    "        train_history_loss += batch_history_loss\n",
    "        train_next_loss += batch_next_loss\n",
    "        num_train_samples += batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        train_pbar.set_postfix({\n",
    "            'loss': f'{avg_batch_loss:.4f}',\n",
    "            'hist': f'{avg_batch_history_loss:.4f}',\n",
    "            'next': f'{avg_batch_next_loss:.4f}'\n",
    "        })\n",
    "        \n",
    "        # Log to wandb (per batch)\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'batch_train_loss': avg_batch_loss,\n",
    "                'batch_train_history_loss': avg_batch_history_loss,\n",
    "                'batch_train_next_loss': avg_batch_next_loss,\n",
    "                'epoch': epoch,\n",
    "                'batch': batch_idx\n",
    "            })\n",
    "    \n",
    "    # Average training losses\n",
    "    avg_train_loss = train_loss / num_train_samples\n",
    "    avg_train_history_loss = train_history_loss / num_train_samples\n",
    "    avg_train_next_loss = train_next_loss / num_train_samples\n",
    "    \n",
    "    # ========== Validation Phase ==========\n",
    "    model.model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_history_loss = 0.0\n",
    "    val_next_loss = 0.0\n",
    "    num_val_samples = 0\n",
    "    \n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\")\n",
    "    with torch.no_grad():\n",
    "        for x, targets in val_pbar:\n",
    "            batch_size = x.shape[0]\n",
    "            \n",
    "            # Forward pass (inference only)\n",
    "            outputs = model.forward(x)\n",
    "            \n",
    "            # Compute losses\n",
    "            for i in range(batch_size):\n",
    "                pred_history, pred_next = model.parse_output(outputs[i])\n",
    "                target_history, target_next = model.parse_output(targets[i])\n",
    "                \n",
    "                history_loss = model.mse_loss(pred_history, target_history)\n",
    "                next_loss = model.mse_loss(pred_next, target_next)\n",
    "                loss = 0.3 * history_loss + next_loss\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_history_loss += history_loss.item()\n",
    "                val_next_loss += next_loss.item()\n",
    "            \n",
    "            num_val_samples += batch_size\n",
    "            \n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({\n",
    "                'loss': f'{val_loss/num_val_samples:.4f}',\n",
    "                'next': f'{val_next_loss/num_val_samples:.4f}'\n",
    "            })\n",
    "    \n",
    "    # Average validation losses\n",
    "    avg_val_loss = val_loss / num_val_samples\n",
    "    avg_val_history_loss = val_history_loss / num_val_samples\n",
    "    avg_val_next_loss = val_next_loss / num_val_samples\n",
    "    \n",
    "    # ========== Logging & Checkpointing ==========\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Save to history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['train_history_loss'].append(avg_train_history_loss)\n",
    "    history['train_next_loss'].append(avg_train_next_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_history_loss'].append(avg_val_history_loss)\n",
    "    history['val_next_loss'].append(avg_val_next_loss)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} - {epoch_time:.1f}s\")\n",
    "    print(f\"  Train - Loss: {avg_train_loss:.4f}, History: {avg_train_history_loss:.4f}, Next: {avg_train_next_loss:.4f}\")\n",
    "    print(f\"  Val   - Loss: {avg_val_loss:.4f}, History: {avg_val_history_loss:.4f}, Next: {avg_val_next_loss:.4f}\")\n",
    "    \n",
    "    # Log to wandb (per epoch)\n",
    "    if wandb.run is not None:\n",
    "        # Weight statistics\n",
    "        W = model.model.W\n",
    "        \n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_history_loss': avg_train_history_loss,\n",
    "            'train_next_loss': avg_train_next_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_history_loss': avg_val_history_loss,\n",
    "            'val_next_loss': avg_val_next_loss,\n",
    "            'weight_mean': W.mean().item(),\n",
    "            'weight_std': W.std().item(),\n",
    "            'weight_max': W.max().item(),\n",
    "            'weight_min': W.min().item(),\n",
    "            'epoch_time': epoch_time\n",
    "        })\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        checkpoint_path = CHECKPOINT_DIR / f'best_model_epoch_{epoch+1}.pt'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.model.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "            'config': config,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  → Saved best model to {checkpoint_path}\")\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = CHECKPOINT_DIR / f'checkpoint_epoch_{epoch+1}.pt'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.model.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "            'config': config,\n",
    "            'history': history,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  → Saved checkpoint to {checkpoint_path}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Test Model\n",
    "\n",
    "Evaluate on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": [
    "print(\"Testing model on test set...\\n\")\n",
    "\n",
    "# Load best model\n",
    "best_checkpoint = list(CHECKPOINT_DIR.glob('best_model_*.pt'))\n",
    "if best_checkpoint:\n",
    "    checkpoint = torch.load(best_checkpoint[0])\n",
    "    model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "else:\n",
    "    print(\"No checkpoint found, using current model\")\n",
    "\n",
    "# Test evaluation\n",
    "model.model.eval()\n",
    "test_loss = 0.0\n",
    "test_history_loss = 0.0\n",
    "test_next_loss = 0.0\n",
    "num_test_samples = 0\n",
    "\n",
    "test_pbar = tqdm(test_loader, desc=\"Testing\")\n",
    "with torch.no_grad():\n",
    "    for x, targets in test_pbar:\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model.forward(x)\n",
    "        \n",
    "        # Compute losses\n",
    "        for i in range(batch_size):\n",
    "            pred_history, pred_next = model.parse_output(outputs[i])\n",
    "            target_history, target_next = model.parse_output(targets[i])\n",
    "            \n",
    "            history_loss = model.mse_loss(pred_history, target_history)\n",
    "            next_loss = model.mse_loss(pred_next, target_next)\n",
    "            loss = 0.3 * history_loss + next_loss\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            test_history_loss += history_loss.item()\n",
    "            test_next_loss += next_loss.item()\n",
    "        \n",
    "        num_test_samples += batch_size\n",
    "        \n",
    "        # Update progress bar\n",
    "        test_pbar.set_postfix({\n",
    "            'loss': f'{test_loss/num_test_samples:.4f}',\n",
    "            'next': f'{test_next_loss/num_test_samples:.4f}'\n",
    "        })\n",
    "\n",
    "# Average test losses\n",
    "avg_test_loss = test_loss / num_test_samples\n",
    "avg_test_history_loss = test_history_loss / num_test_samples\n",
    "avg_test_next_loss = test_next_loss / num_test_samples\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Loss:         {avg_test_loss:.4f}\")\n",
    "print(f\"  History Loss: {avg_test_history_loss:.4f}\")\n",
    "print(f\"  Next Loss:    {avg_test_next_loss:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Log to wandb\n",
    "if wandb.run is not None:\n",
    "    wandb.log({\n",
    "        'test_loss': avg_test_loss,\n",
    "        'test_history_loss': avg_test_history_loss,\n",
    "        'test_next_loss': avg_test_next_loss,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Custom State Configuration Examples\n",
    "\n",
    "Examples of how to configure state in special ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": [
    "# Example 1: Initialize hidden state with specific pattern\n",
    "def init_state_chess_prior(model):\n",
    "    \"\"\"\n",
    "    Initialize state with chess-specific priors.\n",
    "    \"\"\"\n",
    "    model.model.state.zero_()\n",
    "    \n",
    "    # Initialize hidden units with small random values\n",
    "    h_start = model.input_size\n",
    "    h_end = model.input_size + model.hidden_size\n",
    "    model.model.state[h_start:h_end] = torch.randn(model.hidden_size) * 0.01\n",
    "    \n",
    "    # Initialize output units with chess move priors\n",
    "    # (e.g., center moves slightly more likely)\n",
    "    o_start = model.input_size + model.hidden_size\n",
    "    output_state = torch.zeros(model.output_size)\n",
    "    # TODO: Add chess-specific initialization\n",
    "    model.model.state[o_start:] = output_state\n",
    "\n",
    "# Example 2: Warm-start from previous game state\n",
    "def init_state_from_previous(model, previous_state):\n",
    "    \"\"\"\n",
    "    Initialize state from a previous equilibrium.\n",
    "    Useful for sequential game positions.\n",
    "    \"\"\"\n",
    "    model.model.state.copy_(previous_state)\n",
    "    # Clear input portion\n",
    "    model.model.state[:model.input_size] = 0.0\n",
    "\n",
    "# Example 3: Initialize with noise in specific regions\n",
    "def init_state_region_noise(model, region_indices, noise_std=0.1):\n",
    "    \"\"\"\n",
    "    Initialize specific regions with noise.\n",
    "    \"\"\"\n",
    "    model.model.state.zero_()\n",
    "    model.model.state[region_indices] = torch.randn(len(region_indices)) * noise_std\n",
    "\n",
    "print(\"Custom state initialization functions defined.\")\n",
    "print(\"\\nTo use custom initialization, modify the configure_state() method in ChessEqPropLightning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Save/Load Model\n",
    "\n",
    "Save and load trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": [
    "# Save final model manually\n",
    "final_save_path = CHECKPOINT_DIR / 'final_model.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.model.state_dict(),\n",
    "    'config': config,\n",
    "    'history': history,\n",
    "}, final_save_path)\n",
    "print(f\"Final model saved to: {final_save_path}\")\n",
    "\n",
    "# Load model example\n",
    "def load_eqprop_model(checkpoint_path, device='cpu'):\n",
    "    \"\"\"Load a saved EqProp model.\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Recreate model with saved config\n",
    "    loaded_config = checkpoint['config']\n",
    "    loaded_model = ChessEqPropLightning(loaded_config)\n",
    "    loaded_model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Loaded model from {checkpoint_path}\")\n",
    "    if 'epoch' in checkpoint:\n",
    "        print(f\"  Epoch: {checkpoint['epoch']+1}\")\n",
    "    if 'val_loss' in checkpoint:\n",
    "        print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "    \n",
    "    return loaded_model\n",
    "\n",
    "# Example: Load best model\n",
    "best_models = list(CHECKPOINT_DIR.glob('best_model_*.pt'))\n",
    "if best_models:\n",
    "    loaded_model = load_eqprop_model(best_models[0])\n",
    "    print(f\"\\nAccess EqProp module: loaded_model.model\")\n",
    "    print(f\"Weight matrix shape: {loaded_model.model.W.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Finish wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "mosaic": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"Wandb run finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "mosaic": []
   },
   "source": [
    "## Notes\n",
    "\n",
    "### Output Structure\n",
    "\n",
    "The network predicts **9 board states** from white's perspective:\n",
    "1. **8 Historical Board States** (6144 dimensions): Reconstructs the last 8 half-moves (4 full turns)\n",
    "2. **1 Next Board State** (768 dimensions): Predicts the next board position after the current move\n",
    "\n",
    "**Total output: 6,912 dimensions (9 × 768)**\n",
    "\n",
    "This is simpler than encoding moves as from-to vectors - the network learns to predict entire board states, which:\n",
    "- Captures all move types naturally (including castling, en passant, promotion)\n",
    "- Provides richer supervision signal\n",
    "- Enables the network to learn board patterns holistically\n",
    "\n",
    "### Perspective Normalization\n",
    "\n",
    "All boards are flipped to white's perspective:\n",
    "- If it's white's turn: board stays as-is\n",
    "- If it's black's turn: board is flipped vertically and colors are swapped\n",
    "\n",
    "This ensures the network always learns from white's point of view, simplifying the learning task.\n",
    "\n",
    "### Masking for Partial Supervision\n",
    "\n",
    "The training uses masks to weight different parts of the output:\n",
    "- **History reconstruction: 0.3 weight** (auxiliary task - helps learn temporal dynamics)\n",
    "- **Next state prediction: 1.0 weight** (primary task - the actual prediction goal)\n",
    "\n",
    "You can customize these weights in the `training_step()` method.\n",
    "\n",
    "### State Configuration\n",
    "\n",
    "The `configure_state()` method has three modes:\n",
    "\n",
    "1. **'zeros'** (default): Start from zero state\n",
    "2. **'random'**: Small random initialization\n",
    "3. **'custom'**: Temporal prior initialization\n",
    "   - More recent history → less noise (should be easier to recall)\n",
    "   - Older history → more noise (harder to recall)\n",
    "   - Next state → slightly higher noise (it's a prediction, not memory)\n",
    "\n",
    "This biases the network toward better recent memory and uncertain predictions.\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "- **History loss**: MSE between predicted and target historical states\n",
    "- **Next state loss**: MSE between predicted and target next state\n",
    "- **Combined loss**: 0.3 × history_loss + 1.0 × next_loss\n",
    "\n",
    "Logged separately in wandb as `train_history_loss` and `train_next_loss`.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "Currently using MSE loss for both history and prediction. Future additions:\n",
    "- Per-timestep history accuracy\n",
    "- Piece-wise prediction accuracy\n",
    "- Legal position validation\n",
    "- Move extraction from state diff\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Output size is ~7K dimensions (9 board states)\n",
    "- Batch size reduced to 16 for memory efficiency\n",
    "- Hidden layer increased to 2048 to handle temporal complexity\n",
    "- Monitor history vs next-state loss separately to ensure both tasks are learning\n",
    "- The network learns both **memory** (history) and **prediction** (next state) simultaneously"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
